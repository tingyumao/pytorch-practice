{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner Tutorial\n",
    "\n",
    "http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.0000e+00 -8.5899e+09\n",
      " 5.5853e+04 -8.5920e+09\n",
      " 3.0245e+35  1.4532e+34\n",
      "[torch.FloatTensor of size 3x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(3,2) # initialized with random value\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.2731 -1.4716  0.6071\n",
      "-0.4174  0.4679 -0.2702\n",
      "-0.5371  1.9599 -0.8709\n",
      " 0.0819  1.9626 -0.1374\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4,3)\n",
    "print(x)\n",
    "print(x.size()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.4231 -1.6769  1.5896\n",
      "-1.9103 -1.2852 -1.0694\n",
      " 0.3003  2.8159 -1.4190\n",
      "-2.2338  1.3920 -0.5818\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "\n",
      " 0.4231 -1.6769  1.5896\n",
      "-1.9103 -1.2852 -1.0694\n",
      " 0.3003  2.8159 -1.4190\n",
      "-2.2338  1.3920 -0.5818\n",
      "[torch.FloatTensor of size 4x3]\n",
      "\n",
      "\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.ByteTensor of size 4x3]\n",
      "\n",
      "\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.ByteTensor of size 4x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y = torch.randn(4,3)\n",
    "print(x+y)\n",
    "print(torch.add(x,y))\n",
    "print(x+y == torch.add(x,y))\n",
    "print(x+y == x.add_(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n",
      "\n",
      " 1  1  1\n",
      " 1  1  1\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# also torch has no zeros_like attribute.\n",
    "x = torch.ones(2,3)\n",
    "print(x)\n",
    "x = torch.zeros(2,3)\n",
    "print(x+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brige to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "x_np = x.numpy()\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0  0  0\n",
      " 0  0  0\n",
      "[torch.FloatTensor of size 2x3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(x_np)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if cuda available:  False\n"
     ]
    }
   ],
   "source": [
    "print(\"if cuda available: \", torch.cuda.is_available())\n",
    "# let us run this cell only if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables\n",
    "\n",
    "Variables contains .creator, .data and .grad. \n",
    "\n",
    "Another important point\n",
    "\n",
    "Thereâ€™s one more class which is very important for autograd implementation - a Function. Variable and Function are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each variable has a .grad_fn attribute that references a function that has created a function (except for Variables created by the user - these have None as .grad_fn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# initial value should be a torch tensor, not numpy tensor. what is this \"requires_grad\"?\n",
    "x = Variable(torch.ones(2), requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.autograd.function.AddConstantBackward object at 0x1154368b8>\n"
     ]
    }
   ],
   "source": [
    "y = x*x + 2\n",
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 3\n",
      " 3\n",
      "[torch.FloatTensor of size 2]\n",
      " Variable containing:\n",
      " 27\n",
      " 27\n",
      "[torch.FloatTensor of size 2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "out = torch.mean(z)\n",
    "print(y, z, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1\n",
      " 1\n",
      "[torch.FloatTensor of size 2]\n",
      " Variable containing:\n",
      " 3\n",
      " 3\n",
      "[torch.FloatTensor of size 2]\n",
      " Variable containing:\n",
      " 27\n",
      " 27\n",
      "[torch.FloatTensor of size 2]\n",
      " Variable containing:\n",
      " 27\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "Variable containing:\n",
      " 18\n",
      " 18\n",
      "[torch.FloatTensor of size 2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when retain_graph is true, the program will not clear buffer and when run it again, the new grad will be added into \n",
    "# the original buffer.\n",
    "out.backward(retain_graph=True)\n",
    "\n",
    "print(x, y, z, out)\n",
    "print(x.grad) # x.grad[0] = 2x * 6*y * (1/2) = 2*1 * 6*3 * 0.5 = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1547.4574\n",
      "-1259.5884\n",
      "  -74.7870\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "\n",
    "y = x * 2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y * 2\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "  204.8000\n",
      " 2048.0000\n",
      "    0.2048\n",
      "[torch.FloatTensor of size 3]\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients) # if not pass gradients into it, then it will report error since y is not scalar.\n",
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Neural Network\n",
    "\n",
    "Now that you had a glimpse of autograd, nn depends on autograd to define models and differentiate them. An **nn.Module contains layers, and a method forward(input)that returns the output.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### side note on \"super\" use in python\n",
    "\n",
    "It is about **mutiple inheritance**.\n",
    "\n",
    "    class This_is_a_very_long_class_name(object):\n",
    "        def __init__(self):\n",
    "            pass\n",
    "\n",
    "    class Derived(This_is_a_very_long_class_name):\n",
    "        def __init__(self):\n",
    "            super(Derived,self).__init__()   #1\n",
    "            This_is_a_very_long_class_name.__init__(self)    #2\n",
    "\n",
    "**Also in python3+, just \"super().__init__()\" is enough**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1. define cnn kernel / conv2d operations\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5) # input channels, output channels, kernel size\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # 2. define affine operations\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # conv1 layer: conv1 -> relu -> max_pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
    "        # conv2 layer: conv2 -> relu -> max_pooling\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten x and self.num_flat_features(x) return dimension of x.\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        # dense layer 1, 2, 3(no relu)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        # compute the total flatten dimention of input x \n",
    "        size = x.size()[1:] # except the first batch dimension\n",
    "        num_features = 1\n",
    "        # why use for loop here? Is there any simpler way?\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net (\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear (400 -> 120)\n",
      "  (fc2): Linear (120 -> 84)\n",
      "  (fc3): Linear (84 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "print(len(params))\n",
    "print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-0.0282  0.0425 -0.0465  0.1129 -0.0512  0.0629  0.0334 -0.0488  0.0374 -0.1139\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# define input\n",
    "indata = Variable(torch.randn(1,1,32,32))\n",
    "out = net(indata)\n",
    "print(out)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.nn only supports mini-batches** The entire torch.nn package only supports inputs that are a mini-batch of samples, and not a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 38.5980\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target = Variable(torch.arange(1,11))\n",
    "criterion = nn.MSELoss() # define loss function\n",
    "\n",
    "loss = criterion(out, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### back propagation\n",
    "\n",
    "So, when we call loss.backward(), the whole graph is differentiated w.r.t. the loss, and all Variables in the graph will have their .grad Variable accumulated with the gradient.\n",
    "\n",
    "**Each F functional operations can only be used once.** So we need to re-define it after one single backward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "None\n",
      "conv1.bias.grad after backward\n",
      "Variable containing:\n",
      "1.00000e-02 *\n",
      " -2.3051\n",
      "  0.5452\n",
      "  0.0576\n",
      " -2.7216\n",
      "  8.7465\n",
      " -7.7986\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set all gradients into zeros\n",
    "net.zero_grad()\n",
    "\n",
    "print(\"conv1.bias.grad before backward\")\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "out = net(indata) # forward function\n",
    "loss = criterion(out, target)\n",
    "loss.backward()\n",
    "\n",
    "print(\"conv1.bias.grad after backward\")\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd -- update parameter\n",
    "learning_rate = 0.01\n",
    "for p in net.parameters():\n",
    "    p.data.sub_(p.grad.data * learning_rate) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### use optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad()   # zero the gradient buffers\n",
    "out = net(indata) # forward function\n",
    "loss = criterion(out, target)\n",
    "loss.backward()\n",
    "optimizer.step()    # Does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# define transoforms\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))]) # mean, std.\n",
    "# load MNIST datast\n",
    "trainset = datasets.MNIST(root=\"./data\", train=True, transform=trans, download=True)\n",
    "testset = datasets.MNIST(root=\"./data\", train=False, transform=trans, download=True)\n",
    "\n",
    "# define data loader / batch generator\n",
    "\"\"\"\n",
    "    Data loader. Combines a dataset and a sampler, and provides\n",
    "    single- or multi-process iterators over the dataset.\n",
    "\n",
    "    Arguments:\n",
    "        dataset (Dataset): dataset from which to load the data.\n",
    "        batch_size (int, optional): how many samples per batch to load\n",
    "            (default: 1).\n",
    "        shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
    "            at every epoch (default: False).\n",
    "        sampler (Sampler, optional): defines the strategy to draw samples from\n",
    "            the dataset. If specified, ``shuffle`` must be False.\n",
    "        batch_sampler (Sampler, optional): like sampler, but returns a batch of\n",
    "            indices at a time. Mutually exclusive with batch_size, shuffle,\n",
    "            sampler, and drop_last.\n",
    "        num_workers (int, optional): how many subprocesses to use for data\n",
    "            loading. 0 means that the data will be loaded in the main process\n",
    "            (default: 0)\n",
    "        collate_fn (callable, optional): merges a list of samples to form a mini-batch.\n",
    "        pin_memory (bool, optional): If ``True``, the data loader will copy tensors\n",
    "            into CUDA pinned memory before returning them.\n",
    "        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
    "            if the dataset size is not divisible by the batch size. If False and\n",
    "            the size of dataset is not divisible by the batch size, then the last batch\n",
    "            will be smaller. (default: False)\n",
    "    \"\"\"\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKcIPJEX4gaQIP5DUfwFVA92+fhEStAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b5b4d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display a image\n",
    "plt.imshow(np.squeeze(images[0].numpy()))\n",
    "plt.title(labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding=2)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, padding=2)\n",
    "        self.fc1 = nn.Linear(16 * 7 * 7, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.271\n",
      "[1,  4000] loss: 0.175\n",
      "[1,  6000] loss: 0.129\n",
      "[1,  8000] loss: 0.111\n",
      "[1, 10000] loss: 0.098\n",
      "[1, 12000] loss: 0.088\n",
      "[1, 14000] loss: 0.083\n",
      "[2,  2000] loss: 0.066\n",
      "[2,  4000] loss: 0.063\n",
      "[2,  6000] loss: 0.067\n",
      "[2,  8000] loss: 0.053\n",
      "[2, 10000] loss: 0.054\n",
      "[2, 12000] loss: 0.063\n",
      "[2, 14000] loss: 0.056\n"
     ]
    }
   ],
   "source": [
    "# train the network\n",
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.data[0]\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground truth:      7     2     1     0\n",
      "Predicted:      7     2     1     0\n"
     ]
    }
   ],
   "source": [
    "# verify train result\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(\"Ground truth: \", \" \".join('%5s' % labels.numpy()[j] for j in range(4)))\n",
    "\n",
    "outputs = net(Variable(images))\n",
    "_, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % predicted[j] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on GPU\n",
    "\n",
    "TODO: test it on GCP\n",
    "\n",
    "    net.cuda() # transfer net into gpu\n",
    "    \n",
    "    inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda()) # send input and labels into gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
